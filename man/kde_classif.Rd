% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kde_classif.R
\name{kde_classif}
\alias{kde_classif}
\title{Perform KDE classification using locfit.}
\usage{
kde_classif(
  data,
  target_inx,
  pred_inx,
  marg_outs,
  Lambda_i = 0,
  kernel = "gauss",
  alpha_val = 0.3
)
}
\arguments{
\item{data}{Data set; should be of class 'data.frame'.}

\item{target_inx}{Column index for target discrete variable. This variable should be of unit length and the target variable should be of class 'factor'.}

\item{pred_inx}{Column index for predictor variables. The predictor variables can only be of class 'numeric'.}

\item{marg_outs}{Vector of row indices for marginal outliers in the data set. These will be discarded from the KDE classification. One can set this to be an empty vector in case they provide a data set with no marginal outliers.}

\item{Lambda_i}{Vector of Lambda_i values, such that the function returns the misclassified observations for which the KDE ratio exceeds the threshold value of Lambda_i. This can be any vector of values greater than 1, the default choice being 0 which corresponds to a vector of values from 1 to 20 in step sizes of 0.5.}

\item{kernel}{Kernel chosen for KDE. Default choice is 'gauss' for Gaussian kernel. Other options are 'rect', 'trwt', 'tria', 'epan' or 'bisq' for Rectangular, Triweight, Triangle, Epanechnikov and Bisquare kernels - see the documentation of locfit for more details.}

\item{alpha_val}{The value of alpha that determines the kernel bandwidth. The KDE estimator uses an adaptive nearest-neighbour bandwidth to overcome sparsity issues; this uses a bandwidth equal to the kth smallest distance between each point and its neighbours, where k = floor(n*alpha_val) and n is
the number of observations possessing each target index level of interest. Default value is 0.3 and the value can be between 0 and 1 - see the documentation of locfit for more details.}
}
\value{
A list with 2 elements. The first element is a vector of length
equal to length(Lambda_i), including the number of misclassifications for which the KDE ratio exceeds
the elements of Lambda_i. The second element is a list of length equal to length(Lambda_i), with the
indices of the misclassified observation for which the KDE ratio exceeds the elements of Lambda_i.
Setting Lambda_i equal to its default value of 0 will consider Lambda_i to be equal to a vector of
values from 1 up to 20, with step size of 0.5.
}
\description{
This function uses the locfit package to perform classification of a discrete feature using a set
of continuous variables by using Kernel Density Estimation (KDE). The data set should be provided
together with a set of indices of marginally outlying observations, since these observations will
be discarded - one can also provide the data set without any marginal outliers and simply provide
an empty vector for the marginal outliers parameter. A Kernel Density Estimator is built for each
of the levels of the target feature. The value of Lambda_i is there to account for
the number of misclassifications for which the KDE ratio (max KDE value over all levels divided
by the KDE value for the true level for each observation) exceeds Lambda_i. Setting this equal to
0 (default choice) will return results for all Lambda_i values from 1 up to 20 with a step size of 0.5.
}
\examples{
dt <- gen_marg_joint_data(n_obs = 1000, n_disc = 5, n_cont = 5, n_lvls = 3, p_outs = 0.05, jp_outs = 0.2, assoc_target = 1, assoc_vars = c(1, 2), assoc_type = 'linear', seed_num = 1)
discrete_scores <- disc_scores(dt, c(1:5))
continuous_scores <- cont_scores(dt, c(6:10))
marginal_outs <- unique(unlist(marg_outs_scores(data = dt, disc_cols = c(1:5), outscorediscdf = discrete_scores[[2]], outscorecontdf = continuous_scores, outscorediscdfcells = discrete_scores[[3]])))
kde_classification <- kde_classif(data = dt, target_inx = c(1), pred_inx = c(6, 7), marg_outs = marginal_outs, Lambda_i = 0, kernel = 'gauss', alpha_val = 0.3)
kde_classification2 <- kde_classif(data = dt, target_inx = c(1), pred_inx = c(6, 7), marg_outs = marginal_outs, Lambda_i = c(1.5, 5, 7.3, 21.1), kernel = 'epan', alpha_val = 0.5)
kde_classification3 <- kde_classif(data = dt, target_inx = c(1), pred_inx = c(6, 7), marg_outs = marginal_outs, Lambda_i = 8, kernel = 'rect', alpha_val = 0.9)
}
